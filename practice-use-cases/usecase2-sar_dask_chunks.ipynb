{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Usecase: Reflectance Map over Amsterdam\n",
    "\n",
    "In this use case, you will create a mean reflectance map over Amsterdam using satellite aperture radar (SAR) dataset that is provided to you. You will create the mean reflectance map for Amsterdam by reading in binary data for 10 pre-processed satellite images. The reading and computation will be done using dask chunks whose size will be determined by you. The main aim of this use case is to provide an understanding of the dask chunking mechanism. You will perform multiple runs of this analysis chain with different chunking sizes to understand the effect of chunk size on performance of the code for reading and for analysis.\n",
    "\n",
    "### Data used for this notebook\n",
    "- Interferogram stack: Obtained from the caroline project and made available to you at `/project/stursdat/Data/sar_binary_data/`\n",
    "\n",
    "\n",
    "### Setup environment\n",
    "The packages for this use-case are self-contained in the jupyter_dask environment provided to you with this workshop. The following extra packages have been locally installed in the project directory at `/project/stursdat/Software/`\n",
    "\n",
    "stm - space-time matrix from git@github.com:MotionbyLearning/stm.git\n",
    "sarxarray to load the interferogram stack from git@github.com:MotionbyLearning/sarxarray.git\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "--- Initiate a Dask cluster here ---\n",
    "\n",
    "--- you can use the Dask icon on the left of the Jupyter environment ---\n",
    "\n",
    "--- In this demo we init a cluster with 4 workers --- *\n",
    "\n",
    "\\* - Please confirm the number of workers from your instructors before scaling up your dask cluster. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load a SLC stack using SarXarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries - preinstalled in your conda environment\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import sarxarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT MODIFY\n",
    "# Path to data. Need to be absolute. You may need to change this manually\n",
    "path = Path('/project/stursdat/Data/sar_binary_data/')\n",
    "\n",
    "# Metadata of the stack, assume known\n",
    "shape=(2000, 4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a list of SLC paths to read\n",
    "# Explore the files stored in the directory and create a list of the files (format: *_cint_srd.raw) to read\n",
    "# ~2 lines of code\n",
    "\n",
    "# Create two variables with paths to the latitude and longitude files\n",
    "# Geo referenced coordinates\n",
    "# ~2 lines of code\n",
    "f_lat = [path / 'lat.raw']\n",
    "f_lon = [path / 'lon.raw']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define 2D Chunks for reading in parallel with dask\n",
    "# ~1 line of code\n",
    "\n",
    "# Load the SLC dataset - you can do this using the sarxarray function from_binary\n",
    "# The function can be called as:\n",
    "# from_binary(list_of_slc_paths, shape_of_slcs, dtype, dask_chunk_size)\n",
    "# dtype for this dataset is np.complex64 \n",
    "# ~1 line of code\n",
    "\n",
    "# Load coordinates - this can also be done using the same from_binary function of sarxarray\n",
    "# ~2 lines of code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT MODIFY\n",
    "stack = stack.assign_coords(lat = ((\"azimuth\", \"range\"), lat.squeeze().lat.data), lon = ((\"azimuth\", \"range\"), lon.squeeze().lon.data))\n",
    "if stack.shape != [2000, 4000, 10]:\n",
    "    print ('Data not read properly, please check your function')\n",
    "else:\n",
    "    print ('Data read successfully')\n",
    "    stack"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the mean reflectance map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can calculate the mrm using the following command available from the sarxarray library\n",
    "# stack.slcstack.mrm() \n",
    "# Use .compute to persist and calculate the values of the mrm.\n",
    "# ~2 lines of code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the mean reflectance map\n",
    "from matplotlib import pyplot as plt\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(mrm)\n",
    "ax.set_aspect(2)\n",
    "im = mrm.plot(ax=ax, cmap='gray')\n",
    "im.set_clim([0, 40000])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge:\n",
    "\n",
    "Rerun the above workflow for different chunk sizes and analyse the performance of the dask cluster. See if you can identify an optimal chunk size for this problem for the fixed worker size.\n",
    "\n",
    "Hint: Use %%time at the top of a jupyter cell to time the execution time for the cell"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "9e01c548609991304941095191e3797ee41d91e6eab5b724963abbb6a743fe42"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
